# TLG8 ANN活用プラン

本ドキュメントでは、TLG8エンコーダーでの探索負荷を軽減するためのANN（人工ニューラルネットワーク）導入方針をまとめる。

## 1. 目的
- ブロック単位（例: 8x8 RGB）での最適な圧縮設定探索を高速化する。
- 虱潰し探索による全組み合わせ評価を回避し、ANNによる候補提示で探索回数を削減する。

## 2. データ収集
1. 既存エンコーダーにフックを設け、各圧縮フェーズで選択された設定と評価値をログとして抽出する。
2. ログ内容:
   - 入力ブロックの画素データ（正規化済み）
   - 選択された設定ID（最良・次善の組み合わせ）
   - その他圧縮結果メタ情報（エラー量、ビット長など）
3. 収集形式:
   - Pythonスクリプトから扱いやすいバイナリまたはJSON Lines形式
   - データ量を考慮し、分割保存および圧縮対応

## 3. 特徴量設計
- 入力:
  - ブロック画素をRGB→YCoCg等に色空間変換し、正規化する。
  - DCTや局所統計量（平均、分散、勾配）を追加特徴として検討。
- 出力:
  - 各圧縮フェーズの候補設定をクラス分類として扱う。
  - 最適候補に加え、二番目の候補まで出力するよう多クラス分類モデルを利用。

## 4. モデル構成
- 軽量CNNもしくはMLPを想定。
- 各圧縮フェーズごとに専用モデルを用意し、同時に推論できるよう軽量推論ライブラリ（ONNX Runtimeや自前実装）を検討。
- モデルサイズを抑えるため、Depthwise Convolutionや量子化を検証。

## 5. 学習フロー
1. 収集データをPythonの学習パイプラインに投入（PyTorch推奨）。
2. 訓練/検証/テストに分割し、AccuracyやTop-2 Accuracyを指標として評価。
3. 学習後にモデルをONNX形式でエクスポート。
4. モデルバージョン管理および再学習手順のドキュメント化。

## 6. 推論統合
- C++側でONNX Runtimeまたは軽量推論コードを組み込み、各フェーズ開始時にANNから候補リストを取得。
- 候補リストを基に限定的な探索を実施し、ANN結果の妥当性検証を行う。
- fallbackとして従来の虱潰し探索を残し、ANN推定が低精度な場合に備える。

## 7. 評価指標
- エンコード時間短縮率
- 出力ビットレートの変化
- ANN推定のTop-1/Top-2精度
- メモリ使用量および追加レイテンシ

## 8. スケジュール案
1. 収集機構実装・データ取得: 1-2週間
2. 初期モデル作成・評価: 2週間
3. 推論統合と最適化: 2-3週間
4. 長期評価と改善: 継続

## 9. リスクと対策
- データ偏り → 多様な画像データセットで収集。
- 推論誤差による品質劣化 → fallback探索と閾値設定。
- モデルサイズによるメモリ負荷 → 圧縮・量子化を検討。

## 10. 今後のタスク
- データダンプ用C++コードの設計
- Python学習スクリプトのひな型作成
- モデル統合用APIの設計

